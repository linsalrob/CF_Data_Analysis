{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cb9273b-3c73-46b9-a88d-7b4319210d53",
   "metadata": {},
   "source": [
    "# What metadata correlates with the data?\n",
    "\n",
    "At the moment, I'm going to do that in a traditional taxonomic way, e.g. with PCAs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c54371a-1c1e-47af-9061-6271a74807c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import PatchCollection\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.dates as mdates\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import json\n",
    "\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from adjustText import adjust_text\n",
    "\n",
    "# there is a FutureWarning in sklearn StandardScalar which is really annoying. This ignores it.\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87c8dc2-afe7-448b-84d7-ea53fa22e2a5",
   "metadata": {},
   "source": [
    "# Read the data frames and correct any issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fb2499e-ade1-43be-a397-cb32a5e05e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrections = {\n",
    "    \"MGI\" : { \n",
    "        '1112926_20171212_S' : '1447437_20171212_S',\n",
    "        '1128691_20170206_S' : '1128691_20171206_S',\n",
    "        '1255498_20171212_S' : '1590009_20171212_S',\n",
    "        '1316979_20171215_S' : '1651490_20171215_S',\n",
    "        '1598281_20180508_S' : '1588281_20180508_S',\n",
    "        '1723809_20180227_S' : '1085876_20180227_S',\n",
    "        '649354_20170206_S' : '639354_20171206_S',\n",
    "        '652927_20180226_S' : '715927_20180226_S',\n",
    "        '658355_20180301_S' : '658355_20180327_S',\n",
    "        '777851_20170918_S' : '778851_20170918_S',\n",
    "        '788707_20181126_S' : '788707_20181129_S'\n",
    "    },\n",
    "    \"minion\" : {\n",
    "        '1112926_20171212_S' : '1447437_20171212_S',\n",
    "        '1255498_20171212_S' : '1590009_20171212_S',\n",
    "        '1316979_20171215_S' : '1651490_20171215_S',\n",
    "        '1598281_20180508_S' : '1588281_20180508_S',\n",
    "        '698917_20190119_S' : '698917_20180119_S'\n",
    "        }\n",
    "}\n",
    "\n",
    "def read_taxonomy(tax_file, firstchar, sequence_type):\n",
    "    \"\"\"\n",
    "    Read the taxonomy file and return a data frame\n",
    "    \"\"\"\n",
    "    \n",
    "    if sequence_type.lower() == 'mgi':\n",
    "        sequence_type = 'MGI'\n",
    "    elif sequence_type.lower() == 'minion':\n",
    "        sequence_type = 'minion'\n",
    "    else:\n",
    "        print(f\"Sorry. Don't know what {sequence_type} is supposed to be\", sys.stderr)\n",
    "        return None\n",
    "       \n",
    "    df = pd.read_csv(tax_file, sep='\\t', compression='gzip')\n",
    "    df = df[df['taxonomy'].str.contains('k__Bacteria')]\n",
    "    df = df[~df['taxonomy'].str.endswith(f'{firstchar}__')]\n",
    "    df = df.set_index('taxonomy')\n",
    "    df = df.rename(columns=corrections[sequence_type])\n",
    "    df.index = df.index.str.replace(f'{firstchar}__', '').str.replace('Candidatus ', '')\n",
    "    df.index = df.index.str.split(';').str[-1]\n",
    "    \n",
    "    df = df.sort_index(axis=1)\n",
    "    return df\n",
    "\n",
    "def read_metadata(sequence_type):\n",
    "    if sequence_type.lower() == 'mgi':\n",
    "        sequence_type = 'MGI'\n",
    "    elif sequence_type.lower() == 'minion':\n",
    "        sequence_type = 'minion'\n",
    "    else:\n",
    "        print(f\"Sorry. Don't know what {sequence_type} is supposed to be\", sys.stderr)\n",
    "        return None\n",
    "    \n",
    "    metadata = pd.read_csv(\"../Metadata/Metadata.txt\", encoding='windows-1252', sep=\"\\t\", index_col=0)\n",
    "    metadata = metadata[~metadata[sequence_type].isna()]\n",
    "\n",
    "    for ix in metadata.index:\n",
    "        s = metadata.loc[ix, sequence_type]\n",
    "        if s in corrections[sequence_type]:\n",
    "            metadata.loc[ix, sequence_type] = corrections[sequence_type][s]\n",
    "    return metadata\n",
    "\n",
    "def sorted_presence_absence(df1, df2, minrowsum=0, asc_sort=False):\n",
    "    \"\"\"\n",
    "    Join the two tables and return the sorted version\n",
    "    \"\"\"\n",
    "    # filter so we only include samples sequenced on both MGI and MinION\n",
    "    common_columns = df1.columns.intersection(df2.columns)\n",
    "    df1_both = df1[common_columns]\n",
    "    df2_both = df2[common_columns]\n",
    "    \n",
    "    # create a presence/absence matrix\n",
    "    df1_presence = (df1_both > 0).astype(int)\n",
    "    df2_presence = (df2_both > 0).astype(int)*2\n",
    "\n",
    "    # here we filter on the minimum number of columns each taxa is in if requested\n",
    "    if minrowsum > 0:\n",
    "        df1_presence = df1_presence.loc[df1_presence[df1_presence.sum(axis=1) > minrowsum].index]\n",
    "        df2_presence = df2_presence.loc[df2_presence[df2_presence.sum(axis=1) > (2 * minrowsum)].index]\n",
    "    \n",
    "    # combine the two matrices and sort them\n",
    "    both = df1_presence.add(df2_presence, fill_value=0)\n",
    "    sboth = both.loc[both.sum(axis=1).sort_values(ascending=asc_sort).index]\n",
    "    sboth = sboth.sort_index(axis=1) # sort by column names\n",
    "\n",
    "    return sboth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b33971-a925-451c-8239-3dc018d3c73a",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f5a462c-2702-4d2b-a43b-bd006acf0814",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../MinION/Taxonomy/Minion_read_based_annotations_genus.normalised.tsv.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# read the data \u001b[39;00m\n\u001b[1;32m      3\u001b[0m mgi_df \u001b[38;5;241m=\u001b[39m read_taxonomy(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../MGI/Taxonomy/MGI_reads_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtax\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.normalised.tsv.gz\u001b[39m\u001b[38;5;124m\"\u001b[39m, tax[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmgi\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m min_df \u001b[38;5;241m=\u001b[39m \u001b[43mread_taxonomy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../MinION/Taxonomy/Minion_read_based_annotations_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtax\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.normalised.tsv.gz\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtax\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mminion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m mgi_metadata \u001b[38;5;241m=\u001b[39m read_metadata(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMGI\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m minion_metadata \u001b[38;5;241m=\u001b[39m read_metadata(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminion\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 37\u001b[0m, in \u001b[0;36mread_taxonomy\u001b[0;34m(tax_file, firstchar, sequence_type)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSorry. Don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt know what \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msequence_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is supposed to be\u001b[39m\u001b[38;5;124m\"\u001b[39m, sys\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtax_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgzip\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m df \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtaxonomy\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mcontains(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mk__Bacteria\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[1;32m     39\u001b[0m df \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;241m~\u001b[39mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtaxonomy\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfirstchar\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m__\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/io/common.py:755\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    753\u001b[0m         \u001b[38;5;66;03m# error: Incompatible types in assignment (expression has type\u001b[39;00m\n\u001b[1;32m    754\u001b[0m         \u001b[38;5;66;03m# \"GzipFile\", variable has type \"Union[str, BaseBuffer]\")\u001b[39;00m\n\u001b[0;32m--> 755\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[43mgzip\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGzipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[assignment]\u001b[39;49;00m\n\u001b[1;32m    756\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    757\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    758\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcompression_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    759\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    760\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    761\u001b[0m         handle \u001b[38;5;241m=\u001b[39m gzip\u001b[38;5;241m.\u001b[39mGzipFile(\n\u001b[1;32m    762\u001b[0m             \u001b[38;5;66;03m# No overload variant of \"GzipFile\" matches argument types\u001b[39;00m\n\u001b[1;32m    763\u001b[0m             \u001b[38;5;66;03m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcompression_args,\n\u001b[1;32m    767\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/bioinformatics/lib/python3.9/gzip.py:173\u001b[0m, in \u001b[0;36mGzipFile.__init__\u001b[0;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[1;32m    171\u001b[0m     mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fileobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     fileobj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmyfileobj \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    175\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(fileobj, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../MinION/Taxonomy/Minion_read_based_annotations_genus.normalised.tsv.gz'"
     ]
    }
   ],
   "source": [
    "tax='genus'\n",
    "# read the data \n",
    "mgi_df = read_taxonomy(f\"../MGI/Taxonomy/MGI_reads_{tax}.normalised.tsv.gz\", tax[0], \"mgi\")\n",
    "min_df = read_taxonomy(f\"../MinION/Taxonomy/Minion_read_based_annotations_{tax}.normalised.tsv.gz\", tax[0], \"minion\")\n",
    "mgi_metadata = read_metadata(\"MGI\")\n",
    "minion_metadata = read_metadata(\"minion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afc1238-e386-49a8-9c4a-2458ab667689",
   "metadata": {},
   "source": [
    "### Which sequence type\n",
    "\n",
    "Which sequence type are we working with here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3099e1-2a06-4b2b-97f4-0c148ea017b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_type = \"MGI\"\n",
    "# sequence_type = \"minion\"\n",
    "\n",
    "if sequence_type == \"MGI\":\n",
    "    df = mgi_df.T\n",
    "    metadata = mgi_metadata\n",
    "else:\n",
    "    df = min_df.T\n",
    "    metadata = minion_metadata\n",
    "\n",
    "metadata = metadata[~metadata[sequence_type].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0d8c52-4ba3-4e7c-84f9-284086b057d9",
   "metadata": {},
   "source": [
    "## PCA\n",
    "\n",
    "This is taken from the every person is different tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed91042-6fab-45dd-b0d3-ab59754e8eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization/Transformation\n",
    "# Square root transform\n",
    "sqrt_df = np.sqrt(df)\n",
    "\n",
    "# perform the PCA\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "pca_result = pca.fit_transform(sqrt_df)\n",
    "# Create a DataFrame with PCA results\n",
    "pca_df = pd.DataFrame(data=pca_result, index=df.index, columns=['PC1', 'PC2'])\n",
    "\n",
    "# Get loadings\n",
    "loadings = pca.components_.T * np.sqrt(pca.explained_variance_)\n",
    "# Create a DataFrame for loadings with feature names\n",
    "# Select the top 5 most important loadings\n",
    "loadings_df = pd.DataFrame(loadings, index=df.columns, columns=['PC1', 'PC2'])\n",
    "\n",
    "# Create a DataFrame for top loadings\n",
    "top_loadings_df = loadings_df.loc[loadings_df['PC1'].abs().sort_values(ascending=False).index]\n",
    "\n",
    "# Scale the loadings. This scales the df so that scaled_loadings_df has the same min/max as pca_df\n",
    "# Get the min and max for PC1 and PC2 in pca_df\n",
    "pca_min_PC1, pca_max_PC1 = pca_df['PC1'].min(), pca_df['PC1'].max()\n",
    "pca_min_PC2, pca_max_PC2 = pca_df['PC2'].min(), pca_df['PC2'].max()\n",
    "\n",
    "# Get the min and max for PC1 and PC2 in loadings_df\n",
    "loadings_min_PC1, loadings_max_PC1 = loadings_df['PC1'].min(), loadings_df['PC1'].max()\n",
    "loadings_min_PC2, loadings_max_PC2 = loadings_df['PC2'].min(), loadings_df['PC2'].max()\n",
    "\n",
    "scaled_loadings_df = pd.DataFrame()\n",
    "# Scale loadings_df PC1 to match pca_df PC1 range\n",
    "scaled_loadings_df['PC1'] = (\n",
    "    (loadings_df['PC1'] - loadings_min_PC1) / (loadings_max_PC1 - loadings_min_PC1)  # Normalize to 0-1\n",
    "    * (pca_max_PC1 - pca_min_PC1) + pca_min_PC1                                     # Scale to pca_df range\n",
    ")\n",
    "\n",
    "# Scale loadings_df PC2 to match pca_df PC2 range\n",
    "scaled_loadings_df['PC2'] = (\n",
    "    (loadings_df['PC2'] - loadings_min_PC2) / (loadings_max_PC2 - loadings_min_PC2)  # Normalize to 0-1\n",
    "    * (pca_max_PC2 - pca_min_PC2) + pca_min_PC2                                     # Scale to pca_df range\n",
    ")\n",
    "\n",
    "\n",
    "explained_variance = pca.explained_variance_ratio_ * 100\n",
    "pc1_variance = explained_variance[0]\n",
    "pc2_variance = explained_variance[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350e3175-b25b-45b7-8008-04305b607570",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_loadings_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075e38f1-1ce3-413d-9489-5d4d9f415e46",
   "metadata": {},
   "source": [
    "# Correlating Metadata\n",
    "\n",
    "The spreadsheet \"Column Definitions.txt\" contains a list of the columns, what they are, and whether they are numeric or categorical. We use that information to make the following graphs and plots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5845e7-7db8-413e-914a-8d7faa14c34a",
   "metadata": {},
   "source": [
    "## Plot pancreatic insufficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e215e5-07ad-4487-9ca0-0bcf1695b506",
   "metadata": {},
   "source": [
    "## Plot antibiotic usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a0b885-35c1-4f6e-a683-3b4f3c982efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pw_condition = 'Pancreatic insufficiency (PI)'\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "color_map = {'Yes': 'blue', 'No': 'red'}\n",
    "\n",
    "for yn in metadata[pw_condition].dropna().unique():\n",
    "    if yn == '2':\n",
    "        continue\n",
    "    filtered_pca = pca_df[pca_df.index.isin(metadata[metadata[pw_condition] == yn][sequence_type])]\n",
    "    ax.scatter(filtered_pca['PC1'], filtered_pca['PC2'], \n",
    "                color=color_map[yn], label=yn, s=20, alpha=0.7)\n",
    "    \n",
    "# add the loadings ... we only plot maxloadings here\n",
    "maxloadings = 15\n",
    "if len(loadings) < maxloadings:\n",
    "    maxloadings = len(loadings)\n",
    "\n",
    "plotscaler = 2\n",
    "texts = []\n",
    "for i in range(maxloadings):\n",
    "    xpos = top_loadings_df.iloc[i, 0]*plotscaler\n",
    "    ypos = top_loadings_df.iloc[i, 1]*plotscaler\n",
    "    plt.arrow(0, 0, xpos, ypos, \n",
    "              color='black', alpha=0.5, width=0.05)\n",
    "    texts.append(plt.text(xpos, ypos, top_loadings_df.index[i], color='black'))\n",
    "\n",
    "# specifically add Pseudomonas\n",
    "pidx = top_loadings_df.index.get_loc('Pseudomonas')\n",
    "xpos = top_loadings_df.iloc[pidx, 0]*plotscaler\n",
    "ypos = top_loadings_df.iloc[pidx, 1]*plotscaler\n",
    "plt.arrow(0, 0, xpos, ypos, color='black', alpha=0.5, width=0.05)\n",
    "texts.append(plt.text(xpos, ypos, top_loadings_df.index[pidx], color='black'))\n",
    "    \n",
    "adjust_text(texts)\n",
    "\n",
    "# Add labels and legend\n",
    "plt.title(f'{tax.capitalize()}-level taxonomic PCA of the {sequence_type] Sequencing coloured by {pw_condition}')\n",
    "plt.xlabel(f'Principal Component 1 ({pc1_variance:.2f} % of the variation)')\n",
    "plt.ylabel(f'Principal Component 2 ({pc2_variance:.2f} % of the variation)')\n",
    "# plt.legend([])\n",
    "# Display legend with the person labels\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', markerscale=2, title=pw_condition)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"img/pancreatic_insufficieny_pca_{sequence_type}.png\")\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b170b34-c365-47ca-93f4-8d71a01e6616",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathogens = {\n",
    "    \"Streptococcus\",\n",
    "    \"Staphylococcus\",\n",
    "    \"Haemophilus\",\n",
    "    \"Mycobacterium\",\n",
    "    \"Pseudomonas\",\n",
    "    \"Klebsiella\",\n",
    "    \"Moraxella\",\n",
    "    \"Bordetella\",\n",
    "    \"Legionella\",\n",
    "    \"Corynebacterium\",\n",
    "    \"Chlamydia\",\n",
    "    \"Mycoplasma\",\n",
    "    \"Neisseria\",\n",
    "    \"Burkholderia\",\n",
    "    \"Acinetobacter\",\n",
    "    \"Francisella\",\n",
    "    \"Escherichia\",\n",
    "    \"Pasteurella\",\n",
    "    \"Nocardia\",\n",
    "    \"Actinomyces\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc7dc8b-f868-4563-826b-824aa3a668ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pw_condition = 'Antibiotics_YN'\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "color_map = {'Yes': 'red', 'No': 'blue'}\n",
    "\n",
    "pathogen_loading = scaled_loadings_df[scaled_loadings_df.index.isin(pathogens)]\n",
    "non_pathogen_loading = scaled_loadings_df[~scaled_loadings_df.index.isin(pathogens)]\n",
    "tls = top_loadings_df.iloc[:10,:]\n",
    "pathogen_loading = tls[tls.index.isin(pathogens)]\n",
    "non_pathogen_loading = tls[~tls.index.isin(pathogens)]\n",
    "# add the loadings as a kde based on if they are pathogens or not!\n",
    "scaled_loadings_df['pathogen'] = np.where(scaled_loadings_df.index.isin(pathogens), 'Pathogen', 'Non-pathogen')\n",
    "\n",
    "sns.kdeplot(data=non_pathogen_loading, x='PC1', y='PC2', fill=True, alpha=0.3, cmap='Greens', levels=5, ax=ax, bw_adjust=2)\n",
    "sns.kdeplot(data=pathogen_loading, x='PC1', y='PC2', fill=True, alpha=0.3, cmap='Purples', levels=5, ax=ax, bw_adjust=2)\n",
    "# sns.kdeplot(data=non_pathogen_loading, x='PC1', y='PC2', fill=True, alpha=0.5, cmap='Greens', levels=50, thresh=0, ax=ax, bw_adjust=100)\n",
    "\n",
    "# sns.kdeplot(data=scaled_loadings_df, x='PC1', y='PC2', hue='pathogen', fill=True, alpha=0.5, thresh=0, levels=500, ax=ax, bw_adjust=100, cut=0, clip=(-500,500))\n",
    "#sns.kdeplot(data=scaled_loadings_df, x='PC1', y='PC2', hue='pathogen', fill=True, alpha=0.5, levels=500, ax=ax, bw_adjust=100, cut=0)\n",
    "\n",
    "for yn in metadata[pw_condition].dropna().unique():\n",
    "    if yn == '2':\n",
    "        continue\n",
    "    filtered_pca = pca_df[pca_df.index.isin(metadata[metadata[pw_condition] == yn][sequence_type])]\n",
    "    sns.scatterplot(x=filtered_pca['PC1'], y=filtered_pca['PC2'], ax=ax,\n",
    "                color=color_map[yn], label=yn, s=20, alpha=0.7)\n",
    "\n",
    "\n",
    "maxloadings = 15\n",
    "if len(loadings) < maxloadings:\n",
    "    maxloadings = len(loadings)\n",
    "\n",
    "plotscaler = 2\n",
    "texts = []\n",
    "for i in range(maxloadings):\n",
    "    xpos = top_loadings_df.iloc[i, 0]*plotscaler\n",
    "    ypos = top_loadings_df.iloc[i, 1]*plotscaler\n",
    "    linecolour = 'purple' if top_loadings_df.index[i] in pathogens else 'green'\n",
    "    plt.arrow(0, 0, xpos, ypos, \n",
    "              color=linecolour, alpha=0.5, width=0.05)\n",
    "    texts.append(plt.text(xpos, ypos, top_loadings_df.index[i], color=linecolour))\n",
    "\n",
    "# specifically add Pseudomonas\n",
    "pidx = top_loadings_df.index.get_loc('Pseudomonas')\n",
    "xpos = top_loadings_df.iloc[pidx, 0]*plotscaler\n",
    "ypos = top_loadings_df.iloc[pidx, 1]*plotscaler\n",
    "linecolour = 'purple' if top_loadings_df.index[pidx] else 'green'\n",
    "plt.arrow(0, 0, xpos, ypos, color=linecolour, alpha=0.5, width=0.05)\n",
    "texts.append(plt.text(xpos, ypos, top_loadings_df.index[pidx], color=linecolour))\n",
    "    \n",
    "adjust_text(texts)\n",
    "\n",
    "# add a custom legend\n",
    "patches = []\n",
    "patches.append(plt.Line2D([0], [0], marker='o', color='w', label='No antibiotics', \n",
    "                         markerfacecolor='blue', alpha=0.7, markersize=10))\n",
    "patches.append(plt.Line2D([0], [0], marker='o', color='w', label='Antibiotics', \n",
    "                        markerfacecolor='red', alpha=0.7, markersize=10))\n",
    "patches.append(plt.Line2D([0], [0], marker='o', color='w', label='Non-pathogen', \n",
    "                         markerfacecolor='green', alpha=0.3, markersize=10))\n",
    "patches.append(plt.Line2D([0], [0], marker='o', color='w', label='Pathogen', \n",
    "                        markerfacecolor='purple', alpha=0.3, markersize=10))\n",
    "\n",
    "\n",
    "plt.legend(handles=patches, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "    \n",
    "# Add labels and legend\n",
    "plt.title(f'{tax.capitalize()}-level taxonomic PCA of the {sequence_type} Sequencing coloured by {pw_condition}')\n",
    "plt.xlabel(f'Principal Component 1 ({pc1_variance:.2f} % of the variation)')\n",
    "plt.ylabel(f'Principal Component 2 ({pc2_variance:.2f} % of the variation)')\n",
    "# plt.legend([])\n",
    "# Display legend with the person labels\n",
    "#plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', markerscale=2, title=pw_condition)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"img/antibiotics_pca_{sequence_type}.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80643bd2-45d6-47d2-a671-46d6a999ad0d",
   "metadata": {},
   "source": [
    "# Hospital and in-patient vs out-patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c7fedf-028f-4165-acb6-f49b415f4633",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 6))\n",
    "\n",
    "color_map = {'Yes': 'red', 'No': 'blue', 'IP': 'red', 'OP': 'blue', 'RAH': 'red', 'WCH': 'blue'}\n",
    "\n",
    "pathogen_loading = scaled_loadings_df[scaled_loadings_df.index.isin(pathogens)]\n",
    "non_pathogen_loading = scaled_loadings_df[~scaled_loadings_df.index.isin(pathogens)]\n",
    "tls = top_loadings_df.iloc[:10,:]\n",
    "pathogen_loading = tls[tls.index.isin(pathogens)]\n",
    "non_pathogen_loading = tls[~tls.index.isin(pathogens)]\n",
    "# add the loadings as a kde based on if they are pathogens or not!\n",
    "scaled_loadings_df['pathogen'] = np.where(scaled_loadings_df.index.isin(pathogens), 'Pathogen', 'Non-pathogen')\n",
    "\n",
    "for ax in axes:\n",
    "    sns.kdeplot(data=non_pathogen_loading, x='PC1', y='PC2', fill=True, alpha=0.3, cmap='Greens', levels=5, ax=ax, bw_adjust=2)\n",
    "    sns.kdeplot(data=pathogen_loading, x='PC1', y='PC2', fill=True, alpha=0.3, cmap='Purples', levels=5, ax=ax, bw_adjust=2)\n",
    "\n",
    "    \n",
    "maxloadings = 15\n",
    "if len(loadings) < maxloadings:\n",
    "    maxloadings = len(loadings)\n",
    "\n",
    "plotscaler = 2\n",
    "\n",
    "texts = []\n",
    "for axi, pw_condition in enumerate(['IP vs OP', 'Hospital']):\n",
    "    ax = axes[axi]\n",
    "    for yn in metadata[pw_condition].dropna().unique():\n",
    "        if yn == '2':\n",
    "            continue\n",
    "        filtered_pca = pca_df[pca_df.index.isin(metadata[metadata[pw_condition] == yn][sequence_type])]\n",
    "        sns.scatterplot(x=filtered_pca['PC1'], y=filtered_pca['PC2'], ax=ax,\n",
    "                    color=color_map[yn], label=yn, s=20, alpha=0.7)\n",
    "        #axes[axi].legend(title=pw_condition)\n",
    "\n",
    "    \n",
    "    for i in range(maxloadings):\n",
    "        xpos = top_loadings_df.iloc[i, 0]*plotscaler\n",
    "        ypos = top_loadings_df.iloc[i, 1]*plotscaler\n",
    "        linecolour = 'purple' if top_loadings_df.index[i] in pathogens else 'green'\n",
    "        ax.arrow(0, 0, xpos, ypos, \n",
    "                  color=linecolour, alpha=0.5, width=0.05)\n",
    "        texts.append(ax.text(xpos, ypos, top_loadings_df.index[i], color=linecolour))\n",
    "\n",
    "    # specifically add Pseudomonas\n",
    "    pidx = top_loadings_df.index.get_loc('Pseudomonas')\n",
    "    xpos = top_loadings_df.iloc[pidx, 0]*plotscaler\n",
    "    ypos = top_loadings_df.iloc[pidx, 1]*plotscaler\n",
    "    linecolour = 'purple' if top_loadings_df.index[pidx] else 'green'\n",
    "    ax.arrow(0, 0, xpos, ypos, color=linecolour, alpha=0.5, width=0.05)\n",
    "    texts.append(ax.text(xpos, ypos, top_loadings_df.index[pidx], color=linecolour))\n",
    "    \n",
    "    ax.set_xlabel(f'PC 1 ({pc1_variance:.2f} %)')\n",
    "    ax.set_ylabel(f'PC 2 ({pc2_variance:.2f} %)')\n",
    "\n",
    "\n",
    "    # add a custom legend\n",
    "    patches = []\n",
    "    if pw_condition == 'IP vs OP':\n",
    "        patches.append(plt.Line2D([0], [0], marker='o', color='w', label='IP', \n",
    "                                 markerfacecolor='red', alpha=0.5, markersize=5))\n",
    "        patches.append(plt.Line2D([0], [0], marker='o', color='w', label='OP', \n",
    "                                markerfacecolor='blue', alpha=0.5, markersize=5))\n",
    "    else:\n",
    "        patches.append(plt.Line2D([0], [0], marker='o', color='w', label='RAH', \n",
    "                                 markerfacecolor='red', alpha=0.5, markersize=5))\n",
    "        patches.append(plt.Line2D([0], [0], marker='o', color='w', label='WCH', \n",
    "                                markerfacecolor='blue', alpha=0.5, markersize=5))\n",
    "    patches.append(plt.Line2D([0], [0], marker='o', color='w', label='Non-pathogen', \n",
    "                             markerfacecolor='green', alpha=0.5, markersize=5))\n",
    "    patches.append(plt.Line2D([0], [0], marker='o', color='w', label='Pathogen', \n",
    "                            markerfacecolor='purple', alpha=0.5, markersize=5))\n",
    "\n",
    "\n",
    "    ax.legend(handles=patches)\n",
    "    ax.set_title(f'PCA coloured by {pw_condition}')\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"img/ip_op_hosp_pca_{sequence_type}.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd22b46-cfd4-4dd5-bc9e-21c5ed932ce6",
   "metadata": {},
   "source": [
    "## Age and Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48609258-76a1-4d1b-8a2e-cb23ed408f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata['Gender'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd99db4-906a-4c32-bb69-82440918aa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pw_condition = 'Gender'\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "color_map = {'M': 'red', 'F': 'blue'}\n",
    "\n",
    "pathogen_loading = scaled_loadings_df[scaled_loadings_df.index.isin(pathogens)]\n",
    "non_pathogen_loading = scaled_loadings_df[~scaled_loadings_df.index.isin(pathogens)]\n",
    "tls = top_loadings_df.iloc[:10,:]\n",
    "pathogen_loading = tls[tls.index.isin(pathogens)]\n",
    "non_pathogen_loading = tls[~tls.index.isin(pathogens)]\n",
    "# add the loadings as a kde based on if they are pathogens or not!\n",
    "scaled_loadings_df['pathogen'] = np.where(scaled_loadings_df.index.isin(pathogens), 'Pathogen', 'Non-pathogen')\n",
    "\n",
    "sns.kdeplot(data=non_pathogen_loading, x='PC1', y='PC2', fill=True, alpha=0.3, cmap='Greens', levels=5, ax=ax, bw_adjust=2)\n",
    "sns.kdeplot(data=pathogen_loading, x='PC1', y='PC2', fill=True, alpha=0.3, cmap='Purples', levels=5, ax=ax, bw_adjust=2)\n",
    "# sns.kdeplot(data=non_pathogen_loading, x='PC1', y='PC2', fill=True, alpha=0.5, cmap='Greens', levels=50, thresh=0, ax=ax, bw_adjust=100)\n",
    "\n",
    "# sns.kdeplot(data=scaled_loadings_df, x='PC1', y='PC2', hue='pathogen', fill=True, alpha=0.5, thresh=0, levels=500, ax=ax, bw_adjust=100, cut=0, clip=(-500,500))\n",
    "#sns.kdeplot(data=scaled_loadings_df, x='PC1', y='PC2', hue='pathogen', fill=True, alpha=0.5, levels=500, ax=ax, bw_adjust=100, cut=0)\n",
    "\n",
    "for yn in metadata[pw_condition].dropna().unique():\n",
    "    if yn == '2':\n",
    "        continue\n",
    "    filtered_pca = pca_df[pca_df.index.isin(metadata[metadata[pw_condition] == yn][sequence_type])]\n",
    "    sns.scatterplot(x=filtered_pca['PC1'], y=filtered_pca['PC2'], ax=ax,\n",
    "                color=color_map[yn], label=yn, s=20, alpha=0.7)\n",
    "\n",
    "\n",
    "maxloadings = 15\n",
    "if len(loadings) < maxloadings:\n",
    "    maxloadings = len(loadings)\n",
    "\n",
    "plotscaler = 2\n",
    "texts = []\n",
    "for i in range(maxloadings):\n",
    "    xpos = top_loadings_df.iloc[i, 0]*plotscaler\n",
    "    ypos = top_loadings_df.iloc[i, 1]*plotscaler\n",
    "    linecolour = 'purple' if top_loadings_df.index[i] in pathogens else 'green'\n",
    "    plt.arrow(0, 0, xpos, ypos, \n",
    "              color=linecolour, alpha=0.5, width=0.05)\n",
    "    texts.append(plt.text(xpos, ypos, top_loadings_df.index[i], color=linecolour))\n",
    "\n",
    "# specifically add Pseudomonas\n",
    "pidx = top_loadings_df.index.get_loc('Pseudomonas')\n",
    "xpos = top_loadings_df.iloc[pidx, 0]*plotscaler\n",
    "ypos = top_loadings_df.iloc[pidx, 1]*plotscaler\n",
    "linecolour = 'purple' if top_loadings_df.index[pidx] else 'green'\n",
    "plt.arrow(0, 0, xpos, ypos, color=linecolour, alpha=0.5, width=0.05)\n",
    "texts.append(plt.text(xpos, ypos, top_loadings_df.index[pidx], color=linecolour))\n",
    "    \n",
    "adjust_text(texts)\n",
    "\n",
    "# add a custom legend\n",
    "patches = []\n",
    "patches.append(plt.Line2D([0], [0], marker='o', color='w', label='Female', \n",
    "                         markerfacecolor='blue', alpha=0.7, markersize=10))\n",
    "patches.append(plt.Line2D([0], [0], marker='o', color='w', label='Male', \n",
    "                        markerfacecolor='red', alpha=0.7, markersize=10))\n",
    "patches.append(plt.Line2D([0], [0], marker='o', color='w', label='Non-pathogen', \n",
    "                         markerfacecolor='green', alpha=0.3, markersize=10))\n",
    "patches.append(plt.Line2D([0], [0], marker='o', color='w', label='Pathogen', \n",
    "                        markerfacecolor='purple', alpha=0.3, markersize=10))\n",
    "\n",
    "\n",
    "plt.legend(handles=patches, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "    \n",
    "# Add labels and legend\n",
    "plt.title(f'{tax.capitalize()}-level taxonomic PCA of the {sequence_type} Sequencing coloured by {pw_condition}')\n",
    "plt.xlabel(f'Principal Component 1 ({pc1_variance:.2f} % of the variation)')\n",
    "plt.ylabel(f'Principal Component 2 ({pc2_variance:.2f} % of the variation)')\n",
    "# plt.legend([])\n",
    "# Display legend with the person labels\n",
    "#plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', markerscale=2, title=pw_condition)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60715697-7678-4cd1-a99d-f84fe84b2fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pw_condition = 'Age groups'\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "\n",
    "pathogen_loading = scaled_loadings_df[scaled_loadings_df.index.isin(pathogens)]\n",
    "non_pathogen_loading = scaled_loadings_df[~scaled_loadings_df.index.isin(pathogens)]\n",
    "tls = top_loadings_df.iloc[:10,:]\n",
    "pathogen_loading = tls[tls.index.isin(pathogens)]\n",
    "non_pathogen_loading = tls[~tls.index.isin(pathogens)]\n",
    "# add the loadings as a kde based on if they are pathogens or not!\n",
    "scaled_loadings_df['pathogen'] = np.where(scaled_loadings_df.index.isin(pathogens), 'Pathogen', 'Non-pathogen')\n",
    "\n",
    "sns.kdeplot(data=non_pathogen_loading, x='PC1', y='PC2', fill=True, alpha=0.3, cmap='Greens', levels=5, ax=ax, bw_adjust=2)\n",
    "sns.kdeplot(data=pathogen_loading, x='PC1', y='PC2', fill=True, alpha=0.3, cmap='Purples', levels=5, ax=ax, bw_adjust=2)\n",
    "\n",
    "filtered_pca = pca_df.join(metadata['Age groups'])\n",
    "g = sns.scatterplot(filtered_pca, x='PC1', y='PC2', ax=ax, hue='Age groups')\n",
    "\n",
    "\n",
    "\n",
    "maxloadings = 15\n",
    "if len(loadings) < maxloadings:\n",
    "    maxloadings = len(loadings)\n",
    "\n",
    "plotscaler = 2\n",
    "texts = []\n",
    "for i in range(maxloadings):\n",
    "    xpos = top_loadings_df.iloc[i, 0]*plotscaler\n",
    "    ypos = top_loadings_df.iloc[i, 1]*plotscaler\n",
    "    linecolour = 'purple' if top_loadings_df.index[i] in pathogens else 'green'\n",
    "    plt.arrow(0, 0, xpos, ypos, \n",
    "              color=linecolour, alpha=0.5, width=0.05)\n",
    "    texts.append(plt.text(xpos, ypos, top_loadings_df.index[i], color=linecolour))\n",
    "\n",
    "# specifically add Pseudomonas\n",
    "pidx = top_loadings_df.index.get_loc('Pseudomonas')\n",
    "xpos = top_loadings_df.iloc[pidx, 0]*plotscaler\n",
    "ypos = top_loadings_df.iloc[pidx, 1]*plotscaler\n",
    "linecolour = 'purple' if top_loadings_df.index[pidx] else 'green'\n",
    "plt.arrow(0, 0, xpos, ypos, color=linecolour, alpha=0.5, width=0.05)\n",
    "texts.append(plt.text(xpos, ypos, top_loadings_df.index[pidx], color=linecolour))\n",
    "    \n",
    "adjust_text(texts)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# Add labels and legend\n",
    "plt.title(f'{tax.capitalize()}-level taxonomic PCA of the {sequence_type} Sequencing coloured by {pw_condition}')\n",
    "plt.xlabel(f'Principal Component 1 ({pc1_variance:.2f} % of the variation)')\n",
    "plt.ylabel(f'Principal Component 2 ({pc2_variance:.2f} % of the variation)')\n",
    "# plt.legend([])\n",
    "# Display legend with the person labels\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', markerscale=2, title=pw_condition)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39364aa-a63d-4e90-8ef0-dd3b2a227f2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BioinfieConda",
   "language": "python",
   "name": "bioinfieconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
